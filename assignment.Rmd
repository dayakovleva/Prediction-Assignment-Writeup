---
title: "assignment"
output: html_document
---
Prediction Assignment Writeup
Prepared by Daria Yakovleva

Step 1 - loading libraries and dataset. There is a training dataset with almost 20 thousands observations and a test dataset with 20 observations.  
```{r loading}
library('caret')
library('randomForest')
library('rpart')
library('rpart.plot')
library('RColorBrewer')
library('rattle')

data_train <- read.csv("pml-training.csv", header = TRUE, na.strings=c("NA","#DIV/0!",""))
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings=c("NA","#DIV/0!",""))
```

Step 2 - data cleaning. The research doesn't depends on time, so time-dependent parameters can be eliminated. So, the set of parameters will consist of all variables with name consisting of "arm", "forearm", "dumbbell", "belt".  Besides, variables which have a lot of NA or missing value can be removed from the datasets, too. 
```{r cleaning}
missing_obs <- sapply(data_train, function (x) any(is.na(x) | x == ""))
var_for_research <- !missing_obs & grepl("belt|[^(fore)]arm|dumbbell|forearm|classe", names(missing_obs))
data_var_train <- names(missing_obs)[var_for_research]
trainset <- data_train [ ,data_var_train]
```

As a result, the whole training set is to consist of 1 factor variable as a target, while others are numeric and integer. 
```{r cleaningchecking}
table(sapply(trainset[1,], class))
colnames(trainset)
```
Step 3 - data partition. While performing prediction, 70% of dataset will used for training purposes and 30% - for testing. 
```{r paritioning}
inTrain <- createDataPartition(trainset$classe, p = 0.7, list = FALSE)
training <- trainset[inTrain,]
testing <- trainset[-inTrain,]

dim(training)
dim(testing)
```


For prediction the following models will be used: decision trees, random forest, gradient boosting. These models are proper for prediction of factor target variable and normally provide results with more higher quality. 

Step 4 - building decision tree model and checking its quality.

```{r decisiontrees, fig.height = 20, fig.width = 20}
set.seed(12345)
decisTreeFit <- rpart(classe ~ ., data = training, method="class")
decisTreeFit
fancyRpartPlot(decisTreeFit)
```

```{r decisiontreesres}
predictionDT <- predict(decisTreeFit, testing, type = "class")
predictionDT
confusionMatrix(predictionDT, testing$classe)
```
The quality of the model is not high, but it is enough (more than 70%) to consider these presictions not a random one, but conscious.

Step 5 - building a random forest model and checking its quality. 

```{r randomforest}
set.seed(12345)
randForFit <- randomForest(classe ~ ., data = training, ntree = 500)
randForFit
plot(randForFit, main ="Random Forest Model")
```
OOB error rate is low enough and the plot depicts that after building 100 trees the model doesn't achieve significant improvements into error rate reduction. 

```{r randomforestres}
predictionRF <- predict(randForFit, testing, type = "class")
predictionRF
confusionMatrix(predictionRF, testing$classe)
```
Random Forest model shows really good result - the accuracy of predicitons is more than 99%. 

Step 6 - building generalized boosted model and checking its quality.

```{r gbm}
set.seed(12345)
GBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
genBoFit <- train(classe ~ ., data=training, method = "gbm", trControl = GBM, verbose = FALSE)
genBoFit$finalModel

predictionGMB <- predict(genBoFit, newdata = testing)
confusionMatrix(predictionGMB, testing$classe)
confusionMatrix
```
Gradient Doosting model has good accuracy, but it is lower than for Random Forest model. 

Step 7 - application of 20 test cases. For these cases random forest model will be implemented as it has the highest accuracy score. 

```{r testing}
predictionTest <- predict(randForFit, newdata = data_test)
predictionTest
```